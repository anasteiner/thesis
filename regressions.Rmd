## Load libraries

```{r}
# Install all necessary packages
install.packages(c("tidyverse", "sf", "sp", "spgwr", "rgdal", "raster", 
                   "tmap", "ggplot2", "gridExtra", "cowplot", "xts", "zoo"))

# Load all packages
library(tidyverse)
library(sf)
library(sp)
library(spgwr)
library(raster)
library(tmap)
library(ggplot2)
library(gridExtra)
library(cowplot)
library(xts)
library(zoo)
```

```{r}
# Read the datasets
setwd("/Users/anamariasteinercorrea/Desktop/v3 longitudinal diaspora study/Code")
census_data <- read_csv("/Users/anamariasteinercorrea/Desktop/v3 longitudinal diaspora study/Code/census_data.csv")
housing_data <- read_csv("/Users/anamariasteinercorrea/Desktop/v3 longitudinal diaspora study/Code/ffinal_housing_cleaned.csv")
neighborhood_data <- read_csv("/Users/anamariasteinercorrea/Desktop/v3 longitudinal diaspora study/Code/neighborhood_data.csv")
msoa_geometry <- st_read("/Users/anamariasteinercorrea/Desktop/v3 longitudinal diaspora study/Data/MSOA_2011_London_gen_MHW.shp")
```

## Clean and join datasets

```{r}
# Perform the join 
combined_data <- neighborhood_data %>%
  left_join(housing_data, by = c("MSOA11CD", "Year", "MSOA11NM"))

library(tidyr)

# Pivot census_data to wide format, separating columns by Nationality
census_data_wide <- census_data %>%
  pivot_wider(
    names_from = Nationality, 
    values_from = c(Proportion, Dissimilarity_Index, H, Isolation_Index)
  )

# Perform the join 
final_data <- combined_data %>%
  left_join(census_data_wide, by = c("MSOA11CD", "Year", "MSOA11NM"))
```

```{r}
# Join with spatial data
final_data_sf <- final_data %>%
  left_join(msoa_geometry, by = c("MSOA11CD", "MSOA11NM"))

# Convert to sf object
final_data_sf <- st_as_sf(final_data_sf)
```

```{r}
# Clean rows and columns

# Print all column names of final_data_sf
print(colnames(final_data_sf))

# Drop columns by index
final_data_sf <- final_data_sf[, -c(8, 9, 17, 24, 31, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48)]

# Remove rows with any NA values
final_data_sf <- na.omit(final_data_sf)
```

```{r}
# Verify if the data is already an sf object
if (inherits(final_data_sf, "sf")) {
  final_data_sf_sf <- final_data_sf
} else {
  # Check if the geometry column is in a format that can be converted to sf
  if ("geometry" %in% colnames(final_data_sf)) {
    if (inherits(final_data_sf$geometry, "sfc_MULTIPOLYGON")) {
      final_data_sf_sf <- st_as_sf(final_data_sfa)
    } else {
      final_data_sf_sf <- st_as_sf(final_data_sf, wkt = "geometry", crs = 27700)
    }
  } else {
    stop("The geometry column is not in a recognizable format.")
  }
}
```

```{r}
# Convert Religion to dummy variables
library(dplyr)
final_data_sf_sf <- final_data_sf_sf %>%
  mutate_at(vars(Religion), ~as.factor(.)) %>%
  mutate(Religion_Christian = ifelse(Religion == "Christian", 1, 0),
         Religion_Hindu = ifelse(Religion == "Hindu", 1, 0),
         Religion_Jewish = ifelse(Religion == "Jewish", 1, 0),
         Religion_Muslim = ifelse(Religion == "Muslim", 1, 0),
         Religion_NoReligion = ifelse(Religion == "No religion", 1, 0),
         Religion_Sikh = ifelse(Religion == "Sikh", 1, 0))
```

# EDA


```{r}
# View the updated dataset to confirm the removal
print(unique(final_data_sf_sf$Year))
```
```{r}
library(dplyr)
library(sf)

# Define the nationalities
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Calculate the summary statistics for Dissimilarity Index
dissimilarity_summary <- final_data_sf_sf %>%
  st_drop_geometry() %>%
  group_by(Year) %>%
  summarise(
    avg_dissimilarity_index_Bangladesh = mean(Dissimilarity_Index_Bangladesh, na.rm = TRUE),
    avg_dissimilarity_index_Caribbean = mean(Dissimilarity_Index_Caribbean, na.rm = TRUE),
    avg_dissimilarity_index_Poland = mean(Dissimilarity_Index_Poland, na.rm = TRUE),
    avg_dissimilarity_index_Romania = mean(Dissimilarity_Index_Romania, na.rm = TRUE),
    avg_dissimilarity_index_SEAfrica = mean(Dissimilarity_Index_SEAfrica, na.rm = TRUE),
    avg_dissimilarity_index_SouthAmerica = mean(Dissimilarity_Index_SouthAmerica, na.rm = TRUE)
  )

# Calculate the summary statistics for Isolation Index
isolation_summary <- final_data_sf_sf %>%
  st_drop_geometry() %>%
  group_by(Year) %>%
  summarise(
    avg_isolation_index_Bangladesh = mean(Isolation_Index_Bangladesh, na.rm = TRUE),
    avg_isolation_index_Caribbean = mean(Isolation_Index_Caribbean, na.rm = TRUE),
    avg_isolation_index_Poland = mean(Isolation_Index_Poland, na.rm = TRUE),
    avg_isolation_index_Romania = mean(Isolation_Index_Romania, na.rm = TRUE),
    avg_isolation_index_SEAfrica = mean(Isolation_Index_SEAfrica, na.rm = TRUE),
    avg_isolation_index_SouthAmerica = mean(Isolation_Index_SouthAmerica, na.rm = TRUE)
  )

# Calculate the summary statistics for Theil's H Index
thiels_h_summary <- final_data_sf_sf %>%
  st_drop_geometry() %>%
  group_by(Year) %>%
  summarise(
    avg_thiels_h_Bangladesh = mean(H_Bangladesh, na.rm = TRUE),
    avg_thiels_h_Caribbean = mean(H_Caribbean, na.rm = TRUE),
    avg_thiels_h_Poland = mean(H_Poland, na.rm = TRUE),
    avg_thiels_h_Romania = mean(H_Romania, na.rm = TRUE),
    avg_thiels_h_SEAfrica = mean(H_SEAfrica, na.rm = TRUE),
    avg_thiels_h_SouthAmerica = mean(H_SouthAmerica, na.rm = TRUE)
  )

# Print the complete summary tables
print("Dissimilarity Index Summary:")
print(dissimilarity_summary)

print("Isolation Index Summary:")
print(isolation_summary)

print("Theil's H Index Summary:")
print(thiels_h_summary)

```

```{r}
# Drop the geometry column
no_geo_data <- st_drop_geometry(final_data_sf_sf)

# Save the modified dataset to a CSV file
write.csv(no_geo_data, file = "final_data.csv", row.names = FALSE)
```

```{r}
library(spdep)
library(sf)

# Create a spatial weights matrix with zero.policy = TRUE
coords <- st_centroid(st_geometry(final_data_sf_sf))
nb <- poly2nb(final_data_sf_sf)
lw <- nb2listw(nb, zero.policy = TRUE)

# Perform Moran's I calculation
moran.test(final_data_sf_sf$HousingIndex, lw, zero.policy = TRUE)

# Loop through nationalities and calculate Moran's I
nationalities <- c("Dissimilarity_Index_Bangladesh", 
                   "Dissimilarity_Index_Caribbean", 
                   "Dissimilarity_Index_Poland", 
                   "Dissimilarity_Index_Romania", 
                   "Dissimilarity_Index_SEAfrica", 
                   "Dissimilarity_Index_SouthAmerica")

# Loop through nationalities and calculate Moran's I for each
for (nationality in nationalities) {
  print(paste("Calculating Moran's I for:", nationality))
  moran_result <- moran.test(final_data_sf_sf[[nationality]], listw = lw, zero.policy = TRUE)
  print(moran_result)
}
```


```{r}
# Load necessary libraries
library(dplyr)
library(sf)

# Define the nationalities
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Loop through each nationality
for (nationality in nationalities) {
  # Drop geometry before summarizing
  data_no_geometry <- st_drop_geometry(final_data_sf_sf)
  
  # Filter data for the years 2005 and 2021
  data_2005 <- data_no_geometry %>% filter(Year == 2005)
  data_2021 <- data_no_geometry %>% filter(Year == 2021)
  
  # Select relevant columns for 2005
  data_2005 <- data_2005 %>%
    mutate(dissim_2005 = get(paste0("Dissimilarity_Index_", nationality))) %>%
    dplyr::select(MSOA11CD, MSOA11NM, dissim_2005)
  
  # Select relevant columns for 2021
  data_2021 <- data_2021 %>%
    mutate(dissim_2021 = get(paste0("Dissimilarity_Index_", nationality))) %>%
    dplyr::select(MSOA11CD, MSOA11NM, dissim_2021)
  
  # Join the data for comparison
  comparison_data <- left_join(data_2005, data_2021, by = c("MSOA11CD", "MSOA11NM"))
  
  # Calculate the change between 2005 and 2021
  comparison_data <- comparison_data %>%
    mutate(dissim_change = dissim_2021 - dissim_2005)
  
  # Top 10 MSOAs with the biggest increase
  top_increase <- comparison_data %>%
    arrange(desc(dissim_change)) %>%
    slice_head(n = 10)
  
  # Top 10 MSOAs with the biggest decrease
  top_decrease <- comparison_data %>%
    arrange(dissim_change) %>%
    slice_head(n = 10)
  
  # Combine top increase and decrease
  top_combined <- bind_rows(
    top_increase %>% mutate(Change = "Increase"),
    top_decrease %>% mutate(Change = "Decrease")
  )
  
  # Save combined results to CSV file
  write.csv(top_combined, file = paste0("top_10_msoa_changes_", nationality, ".csv"), row.names = FALSE)
}
```

```{r}
# Load necessary libraries
library(dplyr)
library(sf)

# Define the nationalities
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Loop through each nationality
for (nationality in nationalities) {
  # Drop geometry before summarizing
  data_no_geometry <- st_drop_geometry(final_data_sf_sf)
  
  # Calculate the yearly average housing index for each MSOA
  msoa_yearly_housing <- data_no_geometry %>%
    group_by(MSOA11CD, MSOA11NM, Year) %>%
    summarise(
      avg_housing_index = mean(HousingIndex, na.rm = TRUE)
    )
  
  # Calculate the change in housing index for each MSOA by year
  msoa_yearly_housing <- msoa_yearly_housing %>%
    arrange(MSOA11CD, Year) %>%
    group_by(MSOA11CD, MSOA11NM) %>%
    mutate(housing_change = avg_housing_index - lag(avg_housing_index)) %>%
    filter(!is.na(housing_change))  # Remove NA values created by lag
  
  # Loop through each year to find the top 10 increases and decreases
  years <- unique(msoa_yearly_housing$Year)
  
  for (year in years) {
    year_data <- msoa_yearly_housing %>% filter(Year == year)
    
    # Top 10 MSOAs with the biggest increase in Housing Index
    top_increase <- year_data %>%
      arrange(desc(housing_change)) %>%
      slice_head(n = 10)
    
    # Top 10 MSOAs with the biggest decrease in Housing Index
    top_decrease <- year_data %>%
      arrange(housing_change) %>%
      slice_head(n = 10)
    
    # Combine top increase and decrease
    top_combined <- bind_rows(
      top_increase %>% mutate(Change = "Increase"),
      top_decrease %>% mutate(Change = "Decrease")
    )
    
    # Save combined results to CSV file
    write.csv(top_combined, file = paste0("top_10_housing_changes_", nationality, "_", year, ".csv"), row.names = FALSE)
  }
}
```

## Question 1: How are dissimilarity and gentrifation related?

# CCF
```{r}
# Required libraries
library(ggplot2)
library(dplyr)

# Define the nationalities
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Loop over each nationality
for (nationality in nationalities) {
  # Construct the column name for the Dissimilarity Index
  diss_col <- paste0("Dissimilarity_Index_", nationality)
  
  # Calculate the correlation coefficient for the current nationality
  corr_coeff <- cor(final_data_sf_sf$HousingIndex, final_data_sf_sf[[diss_col]])
  
  # Create scatter plot with regression line
  p_scatter <- ggplot(final_data_sf_sf, aes(x = HousingIndex, y = final_data_sf_sf[[diss_col]])) +
    geom_point(color = 'blue') +                     # Scatter plot
    geom_smooth(method = 'lm', se = FALSE, color = 'red') + # Regression line
    labs(
      title = paste('Scatter Plot with Regression Line -', nationality),
      subtitle = paste('Correlation Coefficient:', round(corr_coeff, 2)),
      x = 'Housing Index',
      y = paste('Dissimilarity Index -', nationality)
    ) +
    theme_minimal()
  
  # Save the scatter plot
  ggsave(filename = paste0("scatter_plots/Scatter_", nationality, ".png"), plot = p_scatter, width = 8, height = 6)
  
  # Time-lag analysis: Calculate correlations for each year
  correlation_by_year <- final_data_sf_sf %>%
    group_by(Year) %>%
    summarize(corr_coeff = cor(HousingIndex, .data[[diss_col]]))
  
  # Create bar plot of correlation coefficients over time
  p_bar <- ggplot(correlation_by_year, aes(x = factor(Year), y = corr_coeff)) +
    geom_bar(stat = "identity", fill = 'blue') +
    labs(
      title = paste('Time-Lag Correlation Coefficient -', nationality),
      x = 'Year',
      y = 'Correlation Coefficient'
    ) +
    theme_minimal()
  
  # Save the bar plot
  ggsave(filename = paste0("bar_plots/Bar_", nationality, ".png"), plot = p_bar, width = 8, height = 6)
}
```

# First regression (y = diss, x = HI)
```{r}
# Define the nationalities
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Loop over each nationality to fit the linear model
for (nationality in nationalities) {
  # Construct the column name for the Dissimilarity Index
  diss_col <- paste0("Dissimilarity_Index_", nationality)
  
  # Fit the linear model
  model <- lm(get(diss_col) ~ HousingIndex, data = final_data_sf_sf)
  
  # Print the summary of the model
  cat("\n\nSummary for", nationality, ":\n")
  print(summary(model))
}
```

# Second regression (y = diss, x = HI + neighborhood data)
```{r}
# Define the nationalities
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Loop over each nationality to fit the linear model
for (nationality in nationalities) {
  # Construct the column name for the Dissimilarity Index
  diss_col <- paste0("Dissimilarity_Index_", nationality)
  
  # Fit the linear model with multiple predictors
  model2 <- lm(get(diss_col) ~ HousingIndex + PTAL + MSOA_crime + MSOA_percent_green + 
                              Religion_Christian + Religion_Hindu + Religion_Jewish + 
                              Religion_Muslim + Religion_NoReligion + Religion_Sikh, 
               data = final_data_sf_sf)
  
  # Print the summary of the model
  cat("\n\nSummary for", nationality, ":\n")
  print(summary(model2))
}
```

# Third regression (y = diss, x = HI + neighborhood data + lagged settlement)

```{r}
# Define the nationalities you want to create lagged settlement variables for
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Loop over each nationality to create lagged settlement variables
for (nationality in nationalities) {
  # Create the column name for the current and lagged proportion
  prop_col <- paste0("Proportion_", nationality)
  lagged_col <- paste0("Lagged_Proportion_", nationality)
  change_col <- paste0("Change_in_Settlement_", nationality)
  
  # Create the lagged proportion column with a lag of 5 steps and calculate the change in settlement
  final_data_sf_sf <- final_data_sf_sf %>%
    group_by(MSOA11CD) %>%
    arrange(Year) %>%  # Ensure the data is sorted by Year
    mutate(!!lagged_col := lag(!!sym(prop_col), n = 5),  # Set n = 5 for a 10-year lag (5 steps)
           !!change_col := !!sym(prop_col) - !!sym(lagged_col)) %>%
    ungroup()
}
```

```{r}
# Define the nationalities
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Loop over each nationality to fit the linear model
for (nationality in nationalities) {
  # Construct the column names for the Dissimilarity Index and Lagged Proportion
  diss_col <- paste0("Dissimilarity_Index_", nationality)
  lagged_col <- paste0("Lagged_Proportion_", nationality)
  
  # Fit the linear model with multiple predictors including lagged_proportion
  model3 <- lm(get(diss_col) ~ HousingIndex + PTAL + MSOA_crime + MSOA_percent_green + 
                              Religion_Christian + Religion_Hindu + Religion_Jewish + 
                              Religion_Muslim + Religion_NoReligion + Religion_Sikh + 
                              get(lagged_col), 
               data = final_data_sf_sf)
  
  # Print the summary of the model
  cat("\n\nSummary for", nationality, ":\n")
  print(summary(model3))
}

```
# Modelo 4 con lagged housing

```{r}
# Define the nationalities you want to create lagged settlement variables for
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Loop over each nationality to create lagged settlement variables
for (nationality in nationalities) {
  # Create the column name for the current and lagged proportion
  prop_col <- paste0("Proportion_", nationality)
  lagged_prop_col <- paste0("Lagged_Proportion_", nationality)
  change_prop_col <- paste0("Change_in_Settlement_", nationality)
  
  # Create the lagged proportion column with a lag of 5 steps and calculate the change in settlement
  final_data_sf_sf <- final_data_sf_sf %>%
    group_by(MSOA11CD) %>%
    arrange(Year) %>%  # Ensure the data is sorted by Year
    mutate(!!lagged_prop_col := lag(!!sym(prop_col), n = 5),  # Set n = 5 for a 10-year lag (5 steps)
           !!change_prop_col := !!sym(prop_col) - !!sym(lagged_prop_col)) %>%
    ungroup()
}

# Create the lagged HousingIndex variable with a lag of 5 steps
final_data_sf_sf <- final_data_sf_sf %>%
  group_by(MSOA11CD) %>%
  arrange(Year) %>%  # Ensure the data is sorted by Year
  mutate(Lagged_HousingIndex = lag(HousingIndex, n = 5),  # Set n = 5 for a 10-year lag (5 steps)
         Change_in_HousingIndex = HousingIndex - Lagged_HousingIndex) %>%
  ungroup()

```

```{r}
# Define the nationalities
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Loop over each nationality to fit the linear model
for (nationality in nationalities) {
  # Construct the column names for the Dissimilarity Index and Lagged Proportion
  diss_col <- paste0("Dissimilarity_Index_", nationality)
  lagged_col <- paste0("Lagged_Proportion_", nationality)
  
  # Fit the linear model with multiple predictors including lagged_proportion and Lagged_HousingIndex
  model4 <- lm(get(diss_col) ~ HousingIndex + Lagged_HousingIndex + PTAL + MSOA_crime + MSOA_percent_green + 
                                Religion_Christian + Religion_Hindu + Religion_Jewish + 
                                Religion_Muslim + Religion_NoReligion + Religion_Sikh + 
                                get(lagged_col), 
               data = final_data_sf_sf)
  
  # Print the summary of the model
  cat("\n\nSummary for", nationality, ":\n")
  print(summary(model4))
}
```

# tabla de resultados de modelos
```{r}
# Load necessary libraries
library(stargazer)
library(broom)  # This package will help to convert model summaries to data frames

# Define the nationalities
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Loop over each nationality to fit the models, create the summary tables, and export results to CSV
for (nationality in nationalities) {
  # Construct the column name for the Dissimilarity Index
  diss_col <- paste0("Dissimilarity_Index_", nationality)
  
  # Fit Model 1: with only HousingIndex
  model1 <- lm(get(diss_col) ~ HousingIndex, data = na.omit(final_data_sf_sf))
  
  # Fit Model 2: with multiple predictors
  model2 <- lm(get(diss_col) ~ HousingIndex + PTAL + MSOA_crime + MSOA_percent_green + 
                                 Religion_Christian + Religion_Hindu + Religion_Jewish + 
                                 Religion_Muslim + Religion_NoReligion + Religion_Sikh, 
               data = na.omit(final_data_sf_sf))
  
  # Create the summary table using stargazer for both models
  stargazer(model1, model2, type = "text", title = paste("Summary for", nationality),
            dep.var.labels = paste("Dissimilarity Index -", nationality),
            covariate.labels = c("HousingIndex", "PTAL", "MSOA Crime", "Percent Green",
                                 "Christian", "Hindu", "Jewish", "Muslim", "No Religion", "Sikh"),
            out = paste0(nationality, "_model_comparison.txt"),
            single.row = TRUE, 
            align = TRUE,
            star.cutoffs = c(0.05, 0.01, 0.001))
  
  # Print the title for clarity in console
  cat("\n\nSummary for", nationality, ":\n")
  
  # Print the stargazer output to the console
  print(stargazer(model1, model2, type = "text", title = paste("Summary for", nationality),
                  dep.var.labels = paste("Dissimilarity Index -", nationality),
                  covariate.labels = c("HousingIndex", "PTAL", "MSOA Crime", "Percent Green",
                                       "Christian", "Hindu", "Jewish", "Muslim", "No Religion", "Sikh"),
                  single.row = TRUE, 
                  align = TRUE,
                  star.cutoffs = c(0.05, 0.01, 0.001)))
  
  # Convert model summaries to data frames
  model1_df <- tidy(model1)
  model2_df <- tidy(model2)
  
  # Add a column to distinguish the models
  model1_df$model <- "Model 1"
  model2_df$model <- "Model 2"
  
  # Combine the data frames
  combined_df <- rbind(model1_df, model2_df)
  
  # Save the combined data frame to a CSV file
  write.csv(combined_df, file = paste0(nationality, "_model_results.csv"), row.names = FALSE)
}
```

# GWR (con todos los factores) fon resltados anuales
```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)

# Define the nationalities and the years of interest
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")
years_of_interest <- c(2005, 2011, 2021)

# Loop over each nationality
for (nationality in nationalities) {
  # Construct the column name for the Dissimilarity Index
  diss_col <- paste0("Dissimilarity_Index_", nationality)
  
  # Loop over each year of interest
  for (year in years_of_interest) {
    # Filter data for the current year
    data_year <- final_data_sf_sf %>% filter(Year == year)
    
    # Calculate GWR coefficients
    coords <- st_coordinates(st_centroid(data_year$geometry))
    
    gwr_formula <- as.formula(paste(diss_col, "~ HousingIndex + HousingIndex_Lag2 + MSOA_crime + MSOA_percent_green + PTAL +  Religion_Christian + Religion_Hindu + Religion_Jewish + Religion_Muslim + Religion_NoReligion + Religion_Sikh"))
    
    gwr_result <- gwr(gwr_formula, 
                      data = data_year, 
                      coords = coords, 
                      adapt = 0.1)  # Adjust the bandwidth as needed
    
    # Extract GWR coefficients
    results_df <- as.data.frame(gwr_result$SDF)
    data_year$GWR_Coefficient <- results_df$HousingIndex
    
    # Categorize GWR coefficients into three bins: Negative, Zero, and Positive
    data_year$GWR_Coefficient_Category <- cut(data_year$GWR_Coefficient,
                                              breaks = c(-Inf, 0, Inf),
                                              labels = c("Negative", "Positive"))
    
    # Plot the GWR coefficients for the Housing Index with custom colors
    p_gwr <- ggplot(data_year) +
      geom_sf(aes(fill = GWR_Coefficient_Category)) +
      scale_fill_manual(values = c("Negative" = "yellow", 
                                   "Zero" = "orange", 
                                   "Positive" = "red")) +
      theme_minimal() +
      labs(title = paste("GWR Coefficient for Housing Index -", nationality, year),
           fill = "Coefficient")
    
    # Save the plot
    ggsave(filename = paste0("GWR_Housing_", nationality, "_", year, ".png"), plot = p_gwr, width = 8, height = 6)
  }
}
```

# Modelo 5 gwr con efectos fijos de tiempo (fixed effects)
```{r}
# Load necessary libraries
library(fastDummies)
library(sf)
library(spgwr)
library(ggplot2)

# Define the nationalities
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Create dummy variables for Year
final_data_sf_sf <- dummy_cols(final_data_sf_sf, select_columns = "Year", remove_first_dummy = TRUE)

# Convert the data back to an sf object after adding dummies
final_data_sf_sf <- st_as_sf(final_data_sf_sf)

# Loop over each nationality to perform GWR
for (nationality in nationalities) {
  # Construct the column names for the Dissimilarity Index and Lagged Proportion
  diss_col <- paste0("Dissimilarity_Index_", nationality)
  lagged_prop_col <- paste0("Lagged_Proportion_", nationality)
  
  # Extract the data for the current nationality
  data_year <- final_data_sf_sf
  
  # Get coordinates of the centroids of the geometries
  coords <- st_coordinates(st_centroid(data_year$geometry))
  
  # Perform GWR
  gwr_formula <- as.formula(paste(diss_col, "~ HousingIndex +", lagged_prop_col, "+ MSOA_crime + MSOA_percent_green + PTAL + Religion_Christian + Religion_Hindu + Religion_Jewish + Religion_Muslim + Religion_NoReligion + Religion_Sikh + Year_2007 + Year_2009 + Year_2011 + Year_2013 + Year_2015 + Year_2017 + Year_2019 + Year_2021"))
  
  gwr_result <- gwr(gwr_formula, 
                    data = data_year, 
                    coords = coords, 
                    adapt = 0.1)  # Adjust the bandwidth as needed

  # Print GWR results summary
  print(paste("Summary for", nationality))
  print(summary(gwr_result))
  
  # Extract the GWR coefficients
  results_df <- as.data.frame(gwr_result$SDF)
  data_year$GWR_Coefficient <- results_df$HousingIndex
  
  # Categorize GWR coefficients into three bins: Negative, Zero, and Positive
  data_year$GWR_Coefficient_Category <- cut(data_year$GWR_Coefficient,
                                            breaks = c(-Inf, 0, Inf),
                                            labels = c("Negative", "Positive"))

  # Plot the GWR coefficients for the Housing Index with custom colors
  p_gwr <- ggplot(data_year) +
    geom_sf(aes(fill = GWR_Coefficient_Category)) +
    scale_fill_manual(values = c("Negative" = "yellow", 
                                 "Positive" = "red")) +
    theme_minimal() +
    labs(title = paste("GWR Coefficient for Housing Index -", nationality),
         fill = "Coefficient")
  
  # Save the plot
  ggsave(filename = paste0("GWR_Housing_", nationality, "_General.png"), plot = p_gwr, width = 8, height = 6)
}
```
