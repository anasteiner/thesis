This document shows the code for the Linear and geographically weighted regressions that will analyse the correlation between housing characeristics and segregation data.  

## Load libraries

```{r}
# Install all necessary packages
install.packages(c("tidyverse", "sf", "sp", "spgwr", "rgdal", "raster", 
                   "tmap", "ggplot2", "gridExtra", "cowplot", "xts", "zoo"))

# Load all packages
library(tidyverse)
library(sf)
library(sp)
library(spgwr)
library(raster)
library(tmap)
library(ggplot2)
library(gridExtra)
library(cowplot)
library(xts)
library(zoo)
```

```{r}
# Read the datasets
setwd("/Users/anamariasteinercorrea/thesis")
census_data <- read_csv("/Users/anamariasteinercorrea/Documents/thesis/census_data.csv")
housing_data <- read_csv("/Users/anamariasteinercorrea/Documents/thesis/housing_data.csv")
neighborhood_data <- read_csv("/Users/anamariasteinercorrea/Documents/thesis/neighborhood_data.csv")
msoa_geometry <- st_read("/Users/anamariasteinercorrea/Desktop/v3 longitudinal diaspora study/Data/MSOA_2011_London_gen_MHW.shp")
```

## Clean and join datasets

```{r}
# Perform the join of housing + neighborhood
hn_data <- housing_data %>%
  left_join(neighborhood_data, by = c("MSOA11NM", "MSOA11CD", "Year"))
```

```{r}
# Perform the join of housing + neighborhood + segregation
segregation_analysis <- hn_data %>%
  left_join(census_data, by = c("MSOA11NM", "MSOA11CD", "Year"))
```

```{r}
# Join with spatial data
segregation_final <- segregation_analysis %>%
  left_join(msoa %>% distinct(MSOA11CD, MSOA11NM, .keep_all = TRUE), 
            by = c("MSOA11CD", "MSOA11NM"))

# Convert to sf object
segregation_sf <- st_as_sf(segregation_final)

# Clean the dataset
final_segregation <- segregation_sf %>%
  # Select only the necessary columns and rename them
  dplyr::select(
    MSOA11CD,
    MSOA11NM,
    Year,
    Rent,
    Socialhousing = budget_proportion,
    Owned,
    Houseprice,
    Overoccupation = Occupation,
    geometry,
    Crime = MSOA_crime,
    Greenery = MSOA_percent_green,
    PTAL,
    Nationality,
    Proportion = Proportion.x,
    Diss_Index,
    lagged_diss,
    lagged_Rent,
    lagged_Owned,
    lagged_Houseprice,
    lagged_Occupation
  ) 

filtered_segregation <- final_segregation %>%
  filter(MSOA11NM != "London")
```

## Correlations and Linear regressions

### Correlation matrix for each nationality

```{r}
library(ggcorrplot)
library(dplyr)
library(sf)

# Directory for correlation matrices
dir.create("correlation_matrices", showWarnings = FALSE)

# Loop through each nationality
for (nationality in unique(filtered_segregation$Nationality)) {
  # Filter data for the current nationality and drop geometry
  nat_data <- filtered_segregation %>%
    filter(Nationality == nationality) %>%
    st_drop_geometry()  # Drop the geometry column
  
  # Subset relevant variables for correlation
  correlation_data <- nat_data %>%
    select(
      Diss_Index, Proportion, Rent, Socialhousing, Owned, Houseprice,
      Overoccupation, Crime, Greenery, PTAL,
      lagged_diss
    )
  
  # Remove rows with missing values
  correlation_data <- correlation_data %>%
    na.omit()
  
  # Check if enough variables remain for correlation
  if (nrow(correlation_data) > 0 && ncol(correlation_data) > 1) {
    # Compute the correlation matrix
    corr_matrix <- cor(correlation_data, use = "complete.obs")
    
    # Visualize and save the correlation matrix
    corr_plot <- ggcorrplot(corr_matrix, method = "circle",
                            title = paste("Correlation Matrix for", nationality)) +
      theme_minimal()
    
    ggsave(filename = paste0("correlation_matrices/correlation_matrix_", nationality, ".png"),
           plot = corr_plot, width = 10, height = 6)
  } else {
    message(paste("Not enough valid data for correlation for nationality:", nationality))
  }
}
```

```{r}
Variable	Direction	Strength	Description
Proportion	Positive (Red)	Strong	Higher group proportion is associated with a higher Diss_Index.
Rent	Positive (Red)	Moderate-Strong	Higher rental levels are correlated with higher Diss_Index.
Socialhousing	Positive (Red)	Moderate	Greater social housing provision correlates with higher Diss_Index.
Owned	Negative (Blue)	Moderate	Higher ownership rates are associated with lower Diss_Index.
Houseprice	Negative (Blue)	Moderate	Higher house prices correlate with lower Diss_Index (less segregation).
Overoccupation	Positive (Red)	Moderate	Higher overoccupation is associated with higher Diss_Index.
Crime	Positive (Red)	Weak-Moderate	Higher crime levels are weakly correlated with higher Diss_Index.
Greenery	Negative (Blue)	Weak	More greenery is weakly associated with lower Diss_Index.
PTAL (Transport)	Negative (Blue)	Weak	Better public transport access relates weakly to lower Diss_Index.
Lagged Variables	Mixed	Moderate	Some lagged variables (e.g., lagged_Rent, lagged_diss) show strong correlations.
3. Key Insights
Proportion:
The strongest positive correlation with Diss_Index, suggesting that areas with higher proportions of a specific group also tend to have higher segregation.
Housing Tenure:
Rent and Socialhousing are positively correlated with segregation.
Owned is negatively correlated, indicating that higher ownership rates are linked to lower levels of segregation.
Economic Factors:
Houseprice has a negative correlation, which suggests that higher house prices are linked to lower segregation, possibly due to barriers to access.
Social Indicators:
Overoccupation and Crime show positive correlations, indicating a potential association between socioeconomic stressors and higher segregation.
Environment and Accessibility:
Greenery and PTAL have weak negative correlations, meaning better access to greenery or public transport is slightly associated with lower segregation.
Lagged Variables:
Lagged versions of variables (e.g., lagged_Rent, lagged_diss) are significantly correlated, which suggests temporal persistence in relationships.
4. Implications for Modeling:
Multicollinearity Risk:
The strong correlations between Diss_Index and several predictors (e.g., Proportion, Rent, lagged_diss) suggest multicollinearity issues when building a regression or GWR model.
Use methods like VIF or regularization (Ridge/Lasso) to manage this.
Variable Selection:
Consider dropping or transforming highly correlated predictors (e.g., between Proportion and Diss_Index).
Alternatively, Proportion could serve as a competing dependent variable.
Potential Predictors:
Variables such as Owned, Houseprice, Overoccupation, and Socialhousing can provide meaningful relationships with Diss_Index, as they show moderate correlations and distinct associations.
```

```{r}
# Load required libraries
library(dplyr)

# Replace 'filtered_segregation' with your actual dataset
predictors <- filtered_segregation %>%
  st_drop_geometry() %>%  # Drop geometry if it's an sf object
  select(Proportion, Rent, Socialhousing, Owned, Houseprice,
      Overoccupation, Crime, Greenery, PTAL,
      lagged_diss) %>% 
  na.omit()  # Ensure no missing values

# Function to calculate VIF manually
calculate_vif <- function(data) {
  vif_values <- sapply(names(data), function(var) {
    # Create a formula regressing each variable on all others
    formula <- as.formula(paste(var, "~ ."))
    r_squared <- summary(lm(formula, data = data))$r.squared  # Get R²
    vif <- 1 / (1 - r_squared)  # Calculate VIF
    return(vif)
  })
  return(vif_values)
}

# Calculate VIF for predictors
vif_results <- calculate_vif(predictors)

# Print VIF results
print(vif_results)
```

```{r}
The latest VIF results indicate that all predictors fall within acceptable thresholds, with values ranging from 1.29 to 3.97, suggesting minimal multicollinearity. Variables such as Proportion (1.33), Socialhousing (1.29), Rent (1.54), and Houseprice (1.87) show no multicollinearity concerns, while Overoccupation (3.97) and lagged_diss (3.11) remain slightly higher but still well below problematic levels. These results confirm that the predictors can be included in the model without destabilizing the regression coefficients. Moving forward, I will continue to monitor VIF values when introducing new variables or adjustments to ensure multicollinearity remains within acceptable bounds, maintaining the robustness and interpretability of the analysis.
```

### Scatterplot for individual correlations

```{r}
library(ggplot2)
library(dplyr)

# Ensure directory for scatterplot outputs exists
dir.create("scatterplots", showWarnings = FALSE)

# Specify the variables for scatterplots
x_vars <- c("Rent", "Socialhousing", "Owned", "Houseprice", 
            "Overoccupation", "Crime", "Greenery", "PTAL", "lagged_diss")

# Loop through each nationality
for (nationality in unique(filtered_segregation$Nationality)) {
  # Filter data for the current nationality
  nat_data <- filtered_segregation %>%
    filter(Nationality == nationality)
  
  # Generate scatterplots for each specified variable
  for (x_var in x_vars) {
    if (x_var %in% colnames(nat_data)) {  # Ensure variable exists in the data
      scatter_plot <- ggplot(nat_data, aes_string(x = x_var, y = "Diss_Index")) +
        geom_point(alpha = 0.5, color = "blue") +  # Scatter points
        geom_smooth(method = "lm", se = FALSE, color = "red") +  # Linear trendline
        labs(
          title = paste("Scatterplot for", nationality, "-", x_var),
          x = x_var,
          y = "Dissimilarity Index"
        ) +
        theme_minimal()
      
      # Save the scatterplot
      ggsave(
        filename = paste0("scatterplots/scatterplot_", nationality, "_", x_var, ".png"),
        plot = scatter_plot,
        width = 10,
        height = 6
      )
    } else {
      message(paste("Variable", x_var, "not found for nationality:", nationality))
    }
  }
}
```

```{r}

```

### CCFs for individual correlations

```{r}
library(forecast)

# Create a directory for CCF outputs
dir.create("ccfs", showWarnings = FALSE)

for (nationality in nationalities) {
  # Filter data for the current nationality
  nat_data <- filtered_segregation %>% filter(Nationality == nationality)
  
  for (x_var in x_vars) {
    # Compute the CCF between Dissimilarity Index and the variable
    ccf_plot <- ccf(nat_data$Diss_Index, nat_data[[x_var]], lag.max = 10, plot = TRUE,
                    main = paste("CCF for", nationality, "-", x_var))
    
    # Save the plot
    png(filename = paste0("ccfs/ccf_", nationality, "_", x_var, ".png"), width = 800, height = 600)
    plot(ccf_plot)
    dev.off()
  }
}
```

### Linear regressions

Base regressions (1-5 housing characteristics)
Run separate regressions for each housing variable to assess their individual contributions to the segregation index.
No. 6 Neighborhood data
Add neighborhood-level variables to create a comprehensive model.
No. 7 Lagged settlement model
Incorporate the lagged settlement variable alongside all housing variables to capture temporal dependencies.

```{r}
# Load required libraries
library(tidyverse)
library(car) 
install.packages("stargazer")
library(stargazer)
install.packages("sjPlot")
library(sjPlot)   

# Define variables
housing_variables <- c("Rent", "budget_proportion", "average_owned", "Houseprice", "Occupation", "lagged_diss")
neighborhood_variables <- c("MSOA_crime", "MSOA_percent_green", "PTAL")
nationalities <- c("Bangladesh", "Caribbean", "Poland", "Romania", "SEAfrica", "SouthAmerica")

# Create directory for regression outputs
dir.create("regression_outputs", showWarnings = FALSE)

# Loop over nationalities
for (nationality in nationalities) {
  # Filter data for the current nationality
  nationality_data <- filtered_segregation %>% filter(Nationality == nationality)
  
  # Drop geometry column
  numeric_data <- st_drop_geometry(nationality_data)
  
  # Handle missing values
  numeric_data <- numeric_data %>% filter(complete.cases(select(., all_of(c(housing_variables, neighborhood_variables, "lagged_diss")))))
  
  # Define dependent variable
  y_variable <- "Diss_Index"
  
  # Initialize list to store models
  models <- list()
  
  # 1. Regressions for individual housing variables
  for (housing_var in housing_variables) {
    formula <- as.formula(paste(y_variable, "~", paste0("Diss_Index", housing_var)))
    model <- lm(formula, data = scaled_data)
    models[[paste0("Housing_", housing_var)]] <- model
  }
  
  # 2. Model with lagged settlement
  lagged_formula <- as.formula(paste(y_variable, "~", 
                                     paste(paste0("Diss_Index", housing_variables), collapse = " + "), 
                                     "+ lagged_diss"))
  models[["WithLaggedSettlement"]] <- lm(lagged_formula, data = scaled_data)
  
  # 3. Full model with neighborhood variables
  full_formula <- as.formula(paste(y_variable, "~", 
                                   paste(paste0("Diss_Index", housing_variables), collapse = " + "), 
                                   "+ lagged_diss +", 
                                   paste(paste0("Diss_Index", neighborhood_variables), collapse = " + ")))
  models[["FullModel"]] <- lm(full_formula, data = scaled_data)
  
  # Check for multicollinearity in the full model
  vif_values <- vif(models[["FullModel"]])
  print(vif_values)  # Check if VIF > 5–10
  
  # Save diagnostics plots
  pdf(file = paste0("regression_outputs/Diagnostics_", nationality, "_FullModel.pdf"))
  par(mfrow = c(2, 2))
  plot(models[["FullModel"]])  # Residuals, QQ, leverage
  dev.off()
  
  # Generate regression tables
  try({
    stargazer(models, 
              type = "html", 
              out = paste0("regression_outputs/RegressionSummary_", nationality, ".html"), 
              title = paste("Regression Results for", nationality), 
              digits = 3, 
              star.cutoffs = c(0.05, 0.01, 0.001))
  }, silent = TRUE)
  
  # Styled regression table
  try({
    tab_model(models, 
              file = paste0("regression_outputs/RegressionSummary_", nationality, "_Styled.html"), 
              show.ci = TRUE, show.std = TRUE, dv.labels = paste("Dissimilarity Index -", nationality))
  }, silent = TRUE)
}
```

### Temporal analysis of Linear regressions for policy analysis

```{r}
# Create a directory for temporal analysis outputs
dir.create("temporal_analysis", showWarnings = FALSE)

# Define policy periods
finalest_census_dt <- finalest_census_dt %>%
  mutate(Policy_Period = case_when(
    Year < 2010 ~ "Pre-Policy",
    Year >= 2010 & Year < 2015 ~ "During Policy",
    Year >= 2015 ~ "Post-Policy"
  ))

# Loop through each nationality
for (nationality in nationalities) {
  # Filter data for the current nationality
  nat_data <- finalest_census_dt %>% filter(Nationality == nationality)
  
  # Group by policy period and compute mean diss index
  temporal_summary <- nat_data %>%
    group_by(Policy_Period) %>%
    summarize(
      Mean_Dissimilarity_Index = mean(Dissimilarity_Index, na.rm = TRUE)
    )
  
  # Save the temporal summary
  write.csv(temporal_summary, file = paste0("temporal_analysis/temporal_summary_", nationality, ".csv"), row.names = FALSE)
}
```

## GWR 
Explores spatial variations in these relationships, revealing local heterogeneity.

### GWR with best regression model

```{r}
library(sf)
library(spgwr)
library(dplyr)

# Create a directory for GWR outputs
dir.create("gwr_outputs", showWarnings = FALSE)

# Define predictors and dependent variable
y_var <- "Dissimilarity_Index"
x_vars <- c("Rent", "Overoccupation", "Socialhousing", "Ownership", "Houseprice")

# Loop through nationalities and years
nationalities <- unique(finalest_census_dt$Nationality)
years <- unique(finalest_census_dt$Year)

for (nationality in nationalities) {
  for (year in years) {
    # Filter data for the current nationality and year
    gwr_data <- finalest_census_dt %>%
      filter(Nationality == nationality, Year == year) %>%
      distinct(MSOA11CD, .keep_all = TRUE)  # Ensure unique geometries
    
    # Extract centroids for spatial coordinates
    gwr_data <- gwr_data %>%
      st_as_sf() %>%
      st_transform(crs = 27700)  # Example CRS: British National Grid
    centroids <- st_centroid(gwr_data$geometry)
    coords <- as.data.frame(st_coordinates(centroids))
    gwr_data <- cbind(gwr_data, coords)
    
    # Create formula for GWR
    gwr_formula <- as.formula(paste(y_var, "~", paste(x_vars, collapse = " + ")))
    
    # Fit GWR model
    gwr_model <- gwr.basic(
      formula = gwr_formula,
      data = gwr_data,
      coords = cbind(gwr_data$X, gwr_data$Y),
      bw = gwr.sel(gwr_formula, data = gwr_data, coords = cbind(gwr_data$X, gwr_data$Y))
    )
    
    # Save GWR results
    gwr_results <- as.data.frame(gwr_model$SDF)  # Extract coefficients and residuals
    gwr_results$MSOA11CD <- gwr_data$MSOA11CD  # Add MSOA identifiers

    write.csv(gwr_results, file = paste0("gwr_outputs/gwr_results_", nationality, "_", year, ".csv"), row.names = FALSE)
  }
}
```

```{r}
# Create a directory for cluster maps
dir.create("cluster_maps", showWarnings = FALSE)

# Loop through nationalities and years for cluster maps
for (nationality in nationalities) {
  for (year in years) {
    # Load GWR results
    gwr_results <- read.csv(paste0("gwr_outputs/gwr_results_", nationality, "_", year, ".csv"))
    
    # Join GWR results back to unique geometries
    gwr_map_data <- finalest_census_dt %>%
      filter(Year == year, Nationality == nationality) %>%
      distinct(MSOA11CD, .keep_all = TRUE) %>%
      st_as_sf() %>%
      st_transform(crs = 27700) %>%
      left_join(gwr_results, by = "MSOA11CD")
    
    # Generate cluster maps for each predictor
    for (x_var in x_vars) {
      cluster_map <- ggplot(gwr_map_data) +
        geom_sf(aes_string(fill = x_var), color = NA) +
        scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = paste("Cluster of", x_var)) +
        labs(title = paste("Cluster Analysis of", x_var, "-", nationality, "-", year),
             caption = "Source: GWR Analysis") +
        theme_minimal()
      
      # Save cluster map
      ggsave(filename = paste0("cluster_maps/cluster_map_", x_var, "_", nationality, "_", year, ".png"),
             plot = cluster_map, width = 12, height = 8)
    }
  }
}
```

```{r}
# Create a directory for coefficient maps
dir.create("coefficient_maps", showWarnings = FALSE)

# Loop through nationalities and years to generate coefficient maps
for (nationality in nationalities) {
  for (year in years) {
    # Load GWR results
    gwr_results <- read.csv(paste0("gwr_outputs/gwr_results_", nationality, "_", year, ".csv"))
    
    # Join GWR results back to unique geometries
    gwr_map_data <- finalest_census_dt %>%
      filter(Year == year, Nationality == nationality) %>%
      distinct(MSOA11CD, .keep_all = TRUE) %>%
      st_as_sf() %>%
      st_transform(crs = 27700) %>%
      left_join(gwr_results, by = "MSOA11CD")
    
    # Generate coefficient maps for each predictor
    for (x_var in x_vars) {
      coeff_map <- ggplot(gwr_map_data) +
        geom_sf(aes_string(fill = x_var), color = NA) +
        scale_fill_viridis_c(option = "C", name = paste("Coefficient of", x_var)) +
        labs(title = paste("Effect of", x_var, "on Segregation -", nationality, "-", year),
             caption = "Source: GWR Analysis") +
        theme_minimal()
      
      # Save coefficient map
      ggsave(filename = paste0("coefficient_maps/coeff_map_", x_var, "_", nationality, "_", year, ".png"),
             plot = coeff_map, width = 12, height = 8)
    }
  }
}
```

### Diagnostics of GWR

```{r}
# Required libraries
library(sf)
library(dplyr)
library(ggplot2)
library(spdep)
library(viridis)

# Create output directory for diagnostics
dir.create("gwr_outputs/diagnostics", showWarnings = FALSE)

# Loop through nationalities and years for diagnostics
for (nationality in nationalities) {
  for (year in years) {
    tryCatch({
      # Load the GWR results
      gwr_results <- read.csv(paste0("gwr_outputs/gwr_results_", nationality, "_", year, ".csv"))
      
      # Filter and prepare data
      gwr_data <- finalest_census_dt %>%
        filter(Nationality == nationality, Year == year) %>%
        distinct(MSOA11CD, .keep_all = TRUE) %>%
        st_as_sf() %>%
        st_transform(crs = 27700) %>%
        left_join(gwr_results, by = "MSOA11CD")
      
      # 1. RMSE Calculation
      observed <- gwr_data$Dissimilarity_Index
      predicted <- gwr_results$gwr.pred  # Ensure gwr.pred exists in results
      rmse <- sqrt(mean((observed - predicted)^2, na.rm = TRUE))
      cat("RMSE for GWR (", nationality, ", ", year, "): ", rmse, "\n")
      write.table(data.frame(Nationality = nationality, Year = year, RMSE = rmse),
                  file = "gwr_outputs/diagnostics/RMSE_Summary.txt",
                  row.names = FALSE, append = TRUE)
      
      # 2. Plot Local R-squared
      ggplot(gwr_data) +
        geom_sf(aes(fill = localR2), color = NA) +
        scale_fill_viridis_c() +
        labs(title = paste("Local R-squared Map (", nationality, "-", year, ")"),
             fill = "Local R²") +
        theme_minimal() +
        ggsave(paste0("gwr_outputs/diagnostics/LocalR2_", nationality, "_", year, ".png"),
               width = 10, height = 6)
      
      # 3. Residual Diagnostics
      residuals <- gwr_results$gwr.e  # Ensure gwr.e exists in results
      ggplot(gwr_data) +
        geom_sf(aes(fill = residuals), color = NA) +
        scale_fill_viridis_c() +
        labs(title = paste("Residual Map (", nationality, "-", year, ")"),
             fill = "Residuals") +
        theme_minimal() +
        ggsave(paste0("gwr_outputs/diagnostics/Residuals_", nationality, "_", year, ".png"),
               width = 10, height = 6)
      
      # 4. Moran's I for Residuals
      residuals_sp <- gwr_results$gwr.e  # Spatial residuals
      gwr_nb <- poly2nb(as(gwr_data, "Spatial"))  # Neighborhood structure
      gwr_listw <- nb2listw(gwr_nb, style = "W", zero.policy = TRUE)
      moran <- moran.test(residuals_sp, gwr_listw, zero.policy = TRUE)
      cat("Moran's I for residuals (", nationality, ", ", year, "): ", moran$estimate, "\n")
      write.table(data.frame(Nationality = nationality, Year = year,
                             Moran_I = moran$estimate, P_Value = moran$p.value),
                  file = "gwr_outputs/diagnostics/Moran_Summary.txt",
                  row.names = FALSE, append = TRUE)
    }, error = function(e) {
      cat("Error in processing GWR diagnostics for ", nationality, " in ", year, ": ", e$message, "\n")
    })
  }
}
```

### Filtered years of GWR

```{r}
# Define the years to study
years_to_study <- c(2001, 2011, 2021) # Modify these years as needed

# Filter spatial data for selected years
filtered_data <- final_data_sf_sf %>%
  filter(Year %in% years_to_study) %>%
  left_join(london_data, by = "msoa11cd") %>%
  st_as_sf()

# Loop over nationalities
for (nationality in nationalities) {
  # Filter data for the current nationality and years
  nat_data <- filtered_data %>% filter(Nationality == nationality)
  
  # Ensure spatial features are valid
  nat_data <- nat_data %>% st_make_valid()
  
  # Convert to Spatial* object (required by spgwr)
  nat_spatial <- as(nat_data, "Spatial")
  
  # Bandwidth selection (adaptive GWR)
  bandwidth <- gwr.sel(as.formula(best_formula), data = nat_spatial, coords = coordinates(nat_spatial), gweight = gwr.Gauss)
  
  # Run GWR
  gwr_model <- gwr(as.formula(best_formula), data = nat_spatial, coords = coordinates(nat_spatial), bandwidth = bandwidth, gweight = gwr.Gauss, fit.points = TRUE)
  
  # Extract GWR results
  gwr_results <- as.data.frame(gwr_model$SDF)
  
  # Save results back to spatial data
  nat_data <- cbind(nat_data, gwr_results)
  
  # Save filtered GWR output to a shapefile
  st_write(nat_data, paste0("gwr_outputs/GWR_", nationality, "_FilteredYears.shp"), delete_dsn = TRUE)
  
  # Plot coefficient maps for selected predictors
  for (variable in c("HousingIndex", "RentPrice", "Tenancy", "LaggedSettlement")) {
    ggplot(nat_data) +
      geom_sf(aes_string(fill = variable), color = NA) +
      scale_fill_viridis_c() +
      labs(title = paste("GWR Coefficient Map for", variable, "(", nationality, " - Filtered Years)"), fill = "Coefficient") +
      theme_minimal() +
      ggsave(paste0("gwr_outputs/GWR_Coefficient_Filtered_", nationality, "_", variable, ".png"), width = 8, height = 6)
  }
}
```

