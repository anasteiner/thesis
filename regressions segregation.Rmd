This document shows the code for the Linear and geographically weighted regressions that will analyse the correlation between housing characeristics and segregation data.  

## Load libraries

```{r}
# Install all necessary packages
install.packages(c("tidyverse", "sf", "sp", "spgwr", "rgdal", "raster", 
                   "tmap", "ggplot2", "gridExtra", "cowplot", "xts", "zoo"))

# Load all packages
library(tidyverse)
library(sf)
library(sp)
library(spgwr)
library(ggplot2)
library(gridExtra)
library(cowplot)
library(xts)
library(zoo)
```

```{r}
# Read the datasets
setwd("/Users/anamariasteinercorrea/thesis")
census_data <- read_csv("/Users/anamariasteinercorrea/Documents/thesis/census_data.csv")
housing_data <- read_csv("/Users/anamariasteinercorrea/Documents/thesis/housing_data.csv")
neighborhood_data <- read_csv("/Users/anamariasteinercorrea/Documents/thesis/neighborhood_data.csv")
msoa_geometry <- st_read("/Users/anamariasteinercorrea/Desktop/v3 longitudinal diaspora study/Data/MSOA_2011_London_gen_MHW.shp")
```

## Clean and join datasets

```{r}
# Perform the join of housing + neighborhood
hn_data <- housing_data %>%
  left_join(neighborhood_data, by = c("MSOA11NM", "MSOA11CD", "Year"))

aggregated_hn <- hn_data %>%
  group_by(MSOA11CD, MSOA11NM, Year) %>%  # Group by MSOA and Year
  summarize(across(where(is.numeric), mean, na.rm = TRUE), .groups = "drop")  # Average numeric columns

```

```{r}
# Perform the join of housing + neighborhood + segregation
segregation_analysis <- aggregated_hn %>%
  left_join(census_data, by = c("MSOA11NM", "MSOA11CD", "Year"))
```

```{r}
# Join with spatial data
segregation_final <- segregation_analysis %>%
  left_join(msoa_geometry %>% distinct(MSOA11CD, MSOA11NM, .keep_all = TRUE), 
            by = c("MSOA11CD", "MSOA11NM"))

# Convert to sf object
segregation_sf <- st_as_sf(segregation_final)

# Clean the dataset
final_segregation <- segregation_sf %>%
  # Select only the necessary columns and rename them
  dplyr::select(
    MSOA11CD,
    MSOA11NM,
    Year,
    Rent,
    Socialhousing = budget_proportion,
    Owned,
    Houseprice,
    Overoccupation = Occupation,
    geometry,
    Crime = MSOA_crime,
    Greenery = MSOA_percent_green,
    PTAL,
    Nationality,
    Proportion,
    Diss_Index,
    lagged_diss,
  ) 

filtered_segregation <- final_segregation %>%
  filter(MSOA11NM != "London")
```

## Correlations and Linear regressions

### Correlation matrix for each nationality

```{r}
library(ggcorrplot)
library(dplyr)
library(sf)

# Directory for correlation matrices
dir.create("correlation_matrices", showWarnings = FALSE)

# Loop through each nationality
for (nationality in unique(filtered_segregation$Nationality)) {
  # Filter data for the current nationality and drop geometry
  nat_data <- filtered_segregation %>%
    filter(Nationality == nationality) %>%
    st_drop_geometry()  # Drop the geometry column
  
  # Subset relevant variables for correlation
  correlation_data <- nat_data %>%
    select(
      Diss_Index, Proportion, Rent, Socialhousing, Owned, Houseprice,
      Overoccupation, Crime, Greenery, PTAL,
      lagged_diss
    )
  
  # Remove rows with missing values
  correlation_data <- correlation_data %>%
    na.omit()
  
  # Check if enough variables remain for correlation
  if (nrow(correlation_data) > 0 && ncol(correlation_data) > 1) {
    # Compute the correlation matrix
    corr_matrix <- cor(correlation_data, use = "complete.obs")
    
    # Visualize and save the correlation matrix
    corr_plot <- ggcorrplot(corr_matrix, method = "circle",
                            title = paste("Correlation Matrix for", nationality)) +
      theme_minimal()
    
    ggsave(filename = paste0("correlation_matrices/correlation_matrix_", nationality, ".png"),
           plot = corr_plot, width = 10, height = 6)
  } else {
    message(paste("Not enough valid data for correlation for nationality:", nationality))
  }
}
```

```{r}
Variable	Direction	Strength	Description
Proportion	Positive (Red)	Strong	Higher group proportion is associated with a higher Diss_Index.
Rent	Positive (Red)	Moderate-Strong	Higher rental levels are correlated with higher Diss_Index.
Socialhousing	Positive (Red)	Moderate	Greater social housing provision correlates with higher Diss_Index.
Owned	Negative (Blue)	Moderate	Higher ownership rates are associated with lower Diss_Index.
Houseprice	Negative (Blue)	Moderate	Higher house prices correlate with lower Diss_Index (less segregation).
Overoccupation	Positive (Red)	Moderate	Higher overoccupation is associated with higher Diss_Index.
Crime	Positive (Red)	Weak-Moderate	Higher crime levels are weakly correlated with higher Diss_Index.
Greenery	Negative (Blue)	Weak	More greenery is weakly associated with lower Diss_Index.
PTAL (Transport)	Negative (Blue)	Weak	Better public transport access relates weakly to lower Diss_Index.
Lagged Variables	Mixed	Moderate	Some lagged variables (e.g., lagged_Rent, lagged_diss) show strong correlations.
3. Key Insights
Proportion:
The strongest positive correlation with Diss_Index, suggesting that areas with higher proportions of a specific group also tend to have higher segregation.
Housing Tenure:
Rent and Socialhousing are positively correlated with segregation.
Owned is negatively correlated, indicating that higher ownership rates are linked to lower levels of segregation.
Economic Factors:
Houseprice has a negative correlation, which suggests that higher house prices are linked to lower segregation, possibly due to barriers to access.
Social Indicators:
Overoccupation and Crime show positive correlations, indicating a potential association between socioeconomic stressors and higher segregation.
Environment and Accessibility:
Greenery and PTAL have weak negative correlations, meaning better access to greenery or public transport is slightly associated with lower segregation.
Lagged Variables:
Lagged versions of variables (e.g., lagged_Rent, lagged_diss) are significantly correlated, which suggests temporal persistence in relationships.
4. Implications for Modeling:
Multicollinearity Risk:
The strong correlations between Diss_Index and several predictors (e.g., Proportion, Rent, lagged_diss) suggest multicollinearity issues when building a regression or GWR model.
Use methods like VIF or regularization (Ridge/Lasso) to manage this.
Variable Selection:
Consider dropping or transforming highly correlated predictors (e.g., between Proportion and Diss_Index).
Alternatively, Proportion could serve as a competing dependent variable.
Potential Predictors:
Variables such as Owned, Houseprice, Overoccupation, and Socialhousing can provide meaningful relationships with Diss_Index, as they show moderate correlations and distinct associations.
```

```{r}
# Load required libraries
library(dplyr)

predictors <- filtered_segregation %>%
  st_drop_geometry() %>%  
  select(Proportion, Rent, Socialhousing, Owned, Houseprice,
      Overoccupation, Crime, Greenery, PTAL,
      lagged_diss) %>% 
  na.omit()  # Ensure no missing values

# Function to calculate VIF manually
calculate_vif <- function(data) {
  vif_values <- sapply(names(data), function(var) {
    # Create a formula regressing each variable on all others
    formula <- as.formula(paste(var, "~ ."))
    r_squared <- summary(lm(formula, data = data))$r.squared  # Get RÂ²
    vif <- 1 / (1 - r_squared)  # Calculate VIF
    return(vif)
  })
  return(vif_values)
}

# Calculate VIF for predictors
vif_results <- calculate_vif(predictors)

# Print VIF results
print(vif_results)
```

```{r}
The latest VIF results indicate that all predictors fall within acceptable thresholds, with values ranging from 1.29 to 3.97, suggesting minimal multicollinearity. Variables such as Proportion (1.33), Socialhousing (1.29), Rent (1.54), and Houseprice (1.87) show no multicollinearity concerns, while Overoccupation (3.97) and lagged_diss (3.11) remain slightly higher but still well below problematic levels. These results confirm that the predictors can be included in the model without destabilizing the regression coefficients. Moving forward, I will continue to monitor VIF values when introducing new variables or adjustments to ensure multicollinearity remains within acceptable bounds, maintaining the robustness and interpretability of the analysis.
```

### Scatterplot for individual correlations

```{r}
library(ggplot2)
library(dplyr)

# Ensure directory for scatterplot outputs exists
dir.create("scatterplots", showWarnings = FALSE)

# Specify the variables for scatterplots
x_vars <- c("Rent", "Socialhousing", "Owned", "Houseprice", 
            "Overoccupation", "Crime", "Greenery", "PTAL", "lagged_diss")

# Loop through each nationality
for (nationality in unique(filtered_segregation$Nationality)) {
  # Filter data for the current nationality
  nat_data <- filtered_segregation %>%
    filter(Nationality == nationality)
  
  # Generate scatterplots for each specified variable
  for (x_var in x_vars) {
    if (x_var %in% colnames(nat_data)) {  # Ensure variable exists in the data
      scatter_plot <- ggplot(nat_data, aes_string(x = x_var, y = "Diss_Index")) +
        geom_point(alpha = 0.5, color = "blue") +  # Scatter points
        geom_smooth(method = "lm", se = FALSE, color = "red") +  # Linear trendline
        labs(
          title = paste("Scatterplot for", nationality, "-", x_var),
          x = x_var,
          y = "Dissimilarity Index"
        ) +
        theme_minimal()
      
      # Save the scatterplot
      ggsave(
        filename = paste0("scatterplots/scatterplot_", nationality, "_", x_var, ".png"),
        plot = scatter_plot,
        width = 10,
        height = 6
      )
    } else {
      message(paste("Variable", x_var, "not found for nationality:", nationality))
    }
  }
}
```

### CCFs for individual correlations

```{r}
library(forecast)
library(dplyr)

# Create a directory for CCF outputs
dir.create("ccfs", showWarnings = FALSE)

# Loop through each nationality
for (nationality in unique(filtered_segregation$Nationality)) {
  # Filter data for the current nationality
  nat_data <- filtered_segregation %>%
    filter(Nationality == nationality) %>%
    na.omit()  # Remove rows with NA values
  
  # Loop through specified variables
  for (x_var in x_vars) {
    if (x_var %in% colnames(nat_data)) {  # Ensure variable exists
      # Ensure both variables are numeric
      if (is.numeric(nat_data$Diss_Index) && is.numeric(nat_data[[x_var]])) {
        # Check if there are enough observations
        if (length(nat_data$Diss_Index) > 1 && length(nat_data[[x_var]]) > 1) {
          # Compute the CCF
          png(filename = paste0("ccfs/ccf_", nationality, "_", x_var, ".png"), width = 800, height = 600)
          ccf_result <- ccf(
            nat_data$Diss_Index, nat_data[[x_var]], 
            lag.max = 10, plot = TRUE, 
            main = paste("CCF for", nationality, "-", x_var)
          )
          dev.off()
        } else {
          message(paste("Skipping", x_var, "for", nationality, "- Not enough observations"))
        }
      } else {
        message(paste("Skipping", x_var, "for", nationality, "- Non-numeric data"))
      }
    } else {
      message(paste("Variable", x_var, "not found for nationality:", nationality))
    }
  }
}
```

### Linear regressions

Base regressions (1-5 housing characteristics)
Run separate regressions for each housing variable to assess their individual contributions to the segregation index.
No. 6 Neighborhood data
Add neighborhood-level variables to create a comprehensive model.
No. 7 Lagged settlement model
Incorporate the lagged settlement variable alongside all housing variables to capture temporal dependencies.

```{r}
# Load required libraries
library(tidyverse)

# Scaling all variables
scaled_segregation <- filtered_segregation %>%
  mutate(
    # Housing variables
    scaled_Rent = Rent / 1000,                  # Scale Rent (thousands to smaller range)
    scaled_Socialhousing = Socialhousing / 100,              # Scale Budget (billions to smaller range)
    scaled_Houseprice = Houseprice / 100000,   # Scale Houseprice (hundreds of thousands to smaller range)
    scaled_Overoccupation = Overoccupation / 1000,     # Scale Occupation (hundreds to smaller range)
    scaled_Owned = Owned,                      # Keep Owned unchanged (already 0-1)
    # Neighborhood variables
    scaled_Crime = Crime / 10,                 # Scale Crime (reduce magnitude for alignment)
    scaled_Greenery = Greenery,                # Keep Greenery unchanged (already 0-1)
    scaled_PTAL = PTAL                         # Keep PTAL unchanged (manageable range)
  )
```

```{r}
# Define variables
housing_variables <- c("scaled_Rent", "scaled_Socialhousing", "scaled_Houseprice", "scaled_Overoccupation", "scaled_Owned")
neighborhood_variables <- c("scaled_Crime", "scaled_Greenery", "scaled_PTAL")
all_variables <- c(housing_variables, "lagged_diss", neighborhood_variables)
nationalities <- unique(scaled_segregation$Nationality)

# Create directory for regression outputs
dir.create("regression_outputs", showWarnings = FALSE)

# Loop over nationalities
for (nationality in nationalities) {
  # Filter data for the current nationality
  nationality_data <- scaled_segregation %>%
    filter(Nationality == nationality)
  
  # Check if there are enough rows to proceed
  if (nrow(nationality_data) == 0) {
    warning(paste("No valid data for nationality:", nationality))
    next  # Skip this iteration if no rows are available
  }
  
  # Define dependent variable
  y_variable <- "Diss_Index"
  
  # Initialize list to store models
  models <- list()
  
  # 1. Progressive models for housing characteristics
  for (i in seq_along(housing_variables)) {
    current_vars <- housing_variables[1:i]
    current_formula <- paste(y_variable, "~", paste(current_vars, collapse = " + "))
    model <- lm(as.formula(current_formula), data = nationality_data, na.action = na.exclude)
    models[[paste0("Housing_Progressive_", paste(current_vars, collapse = "_"))]] <- model
  }
  
  # 2. Model with all housing variables + lagged_diss
  housing_lagged_formula <- paste(y_variable, "~", paste(housing_variables, collapse = " + "), "+ lagged_diss")
  housing_lagged_model <- lm(as.formula(housing_lagged_formula), data = nationality_data, na.action = na.exclude)
  models[["Housing_Lagged"]] <- housing_lagged_model
  
  # 3. Full model with all variables
  full_formula <- paste(y_variable, "~", paste(all_variables, collapse = " + "))
  full_model <- lm(as.formula(full_formula), data = nationality_data, na.action = na.exclude)
  models[["FullModel"]] <- full_model
  
  # Save diagnostics plots for all models
  pdf(file = paste0("regression_outputs/Diagnostics_", nationality, ".pdf"))
  par(mfrow = c(2, 2))
  for (model_name in names(models)) {
    plot(models[[model_name]])  # Residuals, QQ, leverage
    title(main = paste("Diagnostics for", model_name))
  }
  dev.off()
  
  # Scale coefficients for table display
  scaled_models <- lapply(models, function(model) {
    # Create a copy of the model and scale the coefficients
    scaled_model <- model
    coefs <- coef(scaled_model) * 100  # Scale coefficients by 100
    attr(scaled_model, "coefficients") <- coefs
    scaled_model
  })
  
  # Generate regression tables with Stargazer
  try({
    print(paste("Generating stargazer table for:", nationality))
    stargazer(
      scaled_models,
      type = "html",
      out = paste0("regression_outputs/RegressionTable_", nationality, "_Cleaned.html"),
      title = paste("Regression Results for", nationality, "(Coefficients x 100)"),
      digits = 3,
      star.cutoffs = c(0.05, 0.01, 0.001),
      dep.var.labels = "Dissimilarity Index",
      
      # Remove formula row
      column.labels = rep("", length(models)),  # Empty column labels to suppress formula row
      column.separate = NULL                   # Ensure no separation based on formulas
    )
  }, silent = FALSE)
  
  # Generate regression tables with tab_model
  try({
    print(paste("Generating tab_model table for:", nationality))
    tab_model(
      scaled_models[[1]], scaled_models[[2]], scaled_models[[3]], scaled_models[["Housing_Lagged"]], scaled_models[["FullModel"]],
      file = paste0("regression_outputs/RegressionTable_", nationality, "_Styled.html"),
      show.ci = TRUE,
      show.std = TRUE,
      dv.labels = paste("Dissimilarity Index -", nationality),
      
      # Apply scaling to coefficients in tab_model
      transform = function(x) x * 100
    )
  }, silent = FALSE)
}
```

## GWR 
Explores spatial variations in these relationships, revealing local heterogeneity.

### GWR with best regression model

```{r}
library(sf)
library(spgwr)
library(dplyr)

# Create a directory for GWR outputs
dir.create("gwr_outputs", showWarnings = FALSE)

# Define predictors and dependent variable
y_var <- "Diss_Index"
x_vars <- c("scaled_Rent", "scaled_Overoccupation", "scaled_Socialhousing", "scaled_Owned", 
            "scaled_Houseprice", "scaled_PTAL", "scaled_Crime", "scaled_Greenery", "lagged_diss")

# Loop through nationalities and years
nationalities <- unique(scaled_segregation$Nationality)
years <- unique(scaled_segregation$Year)

for (nationality in nationalities) {
  for (year in years) {
    # Filter data for the current nationality and year
    gwr_data <- scaled_segregation %>%
      filter(Nationality == nationality, Year == year) %>%
      distinct(MSOA11CD, .keep_all = TRUE)  # Ensure unique geometries
    
    # Check if enough data is available
    if (nrow(gwr_data) < 30) {  # Minimum number of observations for reliable GWR
      message(paste("Skipping GWR for", nationality, year, "- insufficient data"))
      next
    }
    
    # Convert to spatial data and transform CRS
    if (!"geometry" %in% colnames(gwr_data)) {
      message(paste("Skipping GWR for", nationality, year, "- geometry missing"))
      next
    }
    gwr_data <- gwr_data %>%
      st_as_sf() %>%
      st_transform(crs = 27700)  # Example CRS: British National Grid
    
    # Extract centroids for spatial coordinates
    centroids <- st_centroid(gwr_data$geometry)
    coords <- as.data.frame(st_coordinates(centroids))
    gwr_data <- cbind(gwr_data, coords)
    
    # Ensure predictors and dependent variable exist in the dataset
    if (!all(c(y_var, x_vars) %in% colnames(gwr_data))) {
      message(paste("Skipping GWR for", nationality, year, "- missing variables"))
      next
    }
    
    # Create formula for GWR
    gwr_formula <- as.formula(paste(y_var, "~", paste(x_vars, collapse = " + ")))
    
    # Fit GWR model
    tryCatch({
      # Select bandwidth
      bw <- gwr.sel(
        gwr_formula, 
        data = gwr_data, 
        coords = cbind(gwr_data$X, gwr_data$Y),
        adapt = TRUE
      )
      
      # Run GWR
      gwr_model <- gwr.basic(
        formula = gwr_formula,
        data = gwr_data,
        coords = cbind(gwr_data$X, gwr_data$Y),
        bw = bw
      )
      
      # Extract GWR results
      gwr_results <- as.data.frame(gwr_model$SDF)  # Coefficients and residuals
      gwr_results$MSOA11CD <- gwr_data$MSOA11CD  # Add MSOA identifiers
      
      # Save GWR results
      write.csv(
        gwr_results,
        file = paste0("gwr_outputs/gwr_results_", nationality, "_", year, ".csv"),
        row.names = FALSE
      )
      
      message(paste("GWR completed for", nationality, year))
    }, error = function(e) {
      message(paste("GWR failed for", nationality, year, "-", e$message))
    })
  }
}
```

```{r}
library(ggplot2)
library(sf)
library(dplyr)

# Create a directory for coefficient maps
dir.create("coefficient_maps", showWarnings = FALSE)

# Loop through nationalities and years
for (nationality in nationalities) {
  for (year in years) {
    # Load GWR results
    gwr_results_file <- paste0("gwr_outputs/gwr_results_", nationality, "_", year, ".csv")
    if (!file.exists(gwr_results_file)) {
      message(paste("Skipping coefficient map for", nationality, year, "- GWR results not found"))
      next
    }
    
    gwr_results <- read.csv(gwr_results_file)
    
    # Join GWR results back to unique geometries
    gwr_map_data <- filtered_segregation %>%
      filter(Year == year, Nationality == nationality) %>%
      distinct(MSOA11CD, .keep_all = TRUE) %>%
      st_as_sf() %>%
      st_transform(crs = 27700) %>%
      left_join(gwr_results, by = "MSOA11CD")
    
    # Check if spatial data is valid
    if (nrow(gwr_map_data) == 0) {
      message(paste("No spatial data for", nationality, year, "- Skipping coefficient maps"))
      next
    }
    
    # Generate coefficient maps for each predictor
    for (x_var in x_vars) {
      if (!x_var %in% colnames(gwr_map_data)) {
        message(paste("Variable", x_var, "not found in GWR results for", nationality, year))
        next
      }
      
      coeff_map <- ggplot(gwr_map_data) +
        geom_sf(aes_string(fill = x_var), color = NA) +
        scale_fill_viridis_c(option = "C", name = paste("Coefficient of", x_var)) +
        labs(
          title = paste("Effect of", x_var, "on Segregation -", nationality, "-", year),
          caption = "Source: GWR Analysis"
        ) +
        theme_minimal()
      
      # Save coefficient map
      ggsave(
        filename = paste0("coefficient_maps/coeff_map_", x_var, "_", nationality, "_", year, ".png"),
        plot = coeff_map,
        width = 12,
        height = 8
      )
      
      message(paste("Coefficient map saved for", x_var, nationality, year))
    }
  }
}
```

### Diagnostics of GWR

```{r}
# Required libraries
library(sf)
library(dplyr)
library(ggplot2)
library(spdep)
library(viridis)

# Create output directory for diagnostics
dir.create("gwr_outputs/diagnostics", showWarnings = FALSE)

# Loop through nationalities and years for diagnostics
for (nationality in nationalities) {
  for (year in years) {
    tryCatch({
      # Load the GWR results
      gwr_results <- read.csv(paste0("gwr_outputs/gwr_results_", nationality, "_", year, ".csv"))
      
      # Filter and prepare data
      gwr_data <- filtered_segregation %>%
        filter(Nationality == nationality, Year == year) %>%
        distinct(MSOA11CD, .keep_all = TRUE) %>%
        st_as_sf() %>%
        st_transform(crs = 27700) %>%
        left_join(gwr_results, by = "MSOA11CD")
      
      # 1. RMSE Calculation
      observed <- gwr_data$Diss_Index
      predicted <- gwr_results$gwr.pred  # Ensure gwr.pred exists in results
      rmse <- sqrt(mean((observed - predicted)^2, na.rm = TRUE))
      cat("RMSE for GWR (", nationality, ", ", year, "): ", rmse, "\n")
      write.table(data.frame(Nationality = nationality, Year = year, RMSE = rmse),
                  file = "gwr_outputs/diagnostics/RMSE_Summary.txt",
                  row.names = FALSE, append = TRUE)
      
      # 2. Plot Local R-squared
      ggplot(gwr_data) +
        geom_sf(aes(fill = localR2), color = NA) +
        scale_fill_viridis_c() +
        labs(title = paste("Local R-squared Map (", nationality, "-", year, ")"),
             fill = "Local RÂ²") +
        theme_minimal() +
        ggsave(paste0("gwr_outputs/diagnostics/LocalR2_", nationality, "_", year, ".png"),
               width = 10, height = 6)
      
      # 3. Residual Diagnostics
      residuals <- gwr_results$gwr.e  # Ensure gwr.e exists in results
      ggplot(gwr_data) +
        geom_sf(aes(fill = residuals), color = NA) +
        scale_fill_viridis_c() +
        labs(title = paste("Residual Map (", nationality, "-", year, ")"),
             fill = "Residuals") +
        theme_minimal() +
        ggsave(paste0("gwr_outputs/diagnostics/Residuals_", nationality, "_", year, ".png"),
               width = 10, height = 6)
      
      # 4. Moran's I for Residuals
      residuals_sp <- gwr_results$gwr.e  # Spatial residuals
      gwr_nb <- poly2nb(as(gwr_data, "Spatial"))  # Neighborhood structure
      gwr_listw <- nb2listw(gwr_nb, style = "W", zero.policy = TRUE)
      moran <- moran.test(residuals_sp, gwr_listw, zero.policy = TRUE)
      cat("Moran's I for residuals (", nationality, ", ", year, "): ", moran$estimate, "\n")
      write.table(data.frame(Nationality = nationality, Year = year,
                             Moran_I = moran$estimate, P_Value = moran$p.value),
                  file = "gwr_outputs/diagnostics/Moran_Summary.txt",
                  row.names = FALSE, append = TRUE)
    }, error = function(e) {
      cat("Error in processing GWR diagnostics for ", nationality, " in ", year, ": ", e$message, "\n")
    })
  }
}
```

### Filtered years of GWR

```{r}
# Required libraries
library(sf)
library(dplyr)
library(ggplot2)
library(spgwr)
library(viridis)

# Define the years to study
years_to_study <- c(2001, 2011, 2021)  # Modify these years as needed

# Filter spatial data for selected years
filtered_data <- filtered_segregation %>%
  filter(Year %in% years_to_study) %>%
  left_join(london_data, by = "MSOA11CD") %>%
  st_as_sf()

# Create output directory for GWR results
dir.create("gwr_outputs", showWarnings = FALSE)

# Loop over nationalities
for (nationality in nationalities) {
  tryCatch({
    # Filter data for the current nationality and years
    nat_data <- filtered_data %>%
      filter(Nationality == nationality) %>%
      st_make_valid()  # Ensure spatial features are valid
    
    # Check if thereâs enough data
    if (nrow(nat_data) < 30) {  # Arbitrary threshold for minimum data
      message(paste("Skipping GWR for", nationality, "- insufficient data for selected years"))
      next
    }
    
    # Convert to Spatial* object (required by spgwr)
    nat_spatial <- as(nat_data, "Spatial")
    
    # Define the formula for GWR
    best_formula <- "Diss_Index ~ Rent + HousingIndex + Tenancy + LaggedSettlement"
    
    # Bandwidth selection (adaptive GWR)
    bandwidth <- gwr.sel(as.formula(best_formula),
                         data = nat_spatial,
                         coords = coordinates(nat_spatial),
                         gweight = gwr.Gauss)
    
    # Run GWR
    gwr_model <- gwr(as.formula(best_formula),
                     data = nat_spatial,
                     coords = coordinates(nat_spatial),
                     bandwidth = bandwidth,
                     gweight = gwr.Gauss,
                     fit.points = TRUE)
    
    # Extract GWR results
    gwr_results <- as.data.frame(gwr_model$SDF)
    
    # Save results back to spatial data
    nat_data <- cbind(nat_data, gwr_results)
    
    # Save filtered GWR output to a shapefile
    st_write(nat_data, paste0("gwr_outputs/GWR_", nationality, "_FilteredYears.shp"), delete_dsn = TRUE)
    
    # Plot coefficient maps for selected predictors
    for (variable in c("HousingIndex", "Rent", "Tenancy", "LaggedSettlement")) {
      coeff_map <- ggplot(nat_data) +
        geom_sf(aes_string(fill = variable), color = NA) +
        scale_fill_viridis_c(option = "C", name = paste("Coefficient of", variable)) +
        labs(
          title = paste("GWR Coefficient Map for", variable, "(", nationality, " - Selected Years)"),
          fill = "Coefficient"
        ) +
        theme_minimal()
      
      # Save the coefficient map
      ggsave(
        filename = paste0("gwr_outputs/GWR_Coefficient_Filtered_", nationality, "_", variable, ".png"),
        plot = coeff_map,
        width = 8,
        height = 6
      )
    }
    
    message(paste("GWR completed for", nationality, "- selected years"))
  }, error = function(e) {
    message(paste("Error processing GWR for", nationality, ":", e$message))
  })
}
```

